{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr as pyr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pyranges as pr\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.feature_selection import RFE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15774323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcf = pyr.read_r(\"CTCF.rds\")\n",
    "stat = pyr.read_r(\"STAT3.rds\")\n",
    "ets = pyr.read_r(\"ETS1.rds\")\n",
    "myod = pyr.read_r(\"MYOD1.rds\")\n",
    "fosl = pyr.read_r(\"FOSL2.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcf_chip = pr.read_bed(\"CTCF_remap.bed\", as_df=True)\n",
    "stat_chip = pr.read_bed(\"STAT3_remap.bed\", as_df=True)\n",
    "ets_chip = pr.read_bed(\"ETS1_remap.bed\", as_df=True)\n",
    "myod_chip = pr.read_bed(\"MYOD1_remap.bed\", as_df=True)\n",
    "fosl_chip = pr.read_bed(\"FOSL2_remap.bed\", as_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=ctcf_chip[\"Score\"],\n",
    "                         mode=\"lines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c53dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcf = ctcf[None]\n",
    "stat = stat[None]\n",
    "ets = ets[None]\n",
    "myod = myod[None]\n",
    "fosl = fosl[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadce1ad",
   "metadata": {},
   "source": [
    "## 1. Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d02e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tf, name):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    filters_list = [10,20,30,40,50,60]\n",
    "    \n",
    "    precisions_list = []\n",
    "    \n",
    "    for filtr in filters_list:\n",
    "\n",
    "        filt = tf[\"tfbs\"].astype(int) <= filtr\n",
    "\n",
    "        tf_masked = tf[filt]\n",
    "\n",
    "        true_positives = tf_masked[\"tfbs\"].value_counts().iloc[1]\n",
    "        positives = tf_masked[\"tfbs\"].count()\n",
    "\n",
    "        precision = round((true_positives / positives) * 100, 2) \n",
    "\n",
    "        precisions_list.append(precision)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=filters_list,\n",
    "                             y=precisions_list))\n",
    "\n",
    "        \n",
    "    fig.update_layout(title = name)\n",
    "            \n",
    "    fig.show()\n",
    "    print(precisions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd94eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(ctcf, \"CTCF\")\n",
    "#precision(stat, \"STAT3\")\n",
    "#precision(ets, \"ETS1\")\n",
    "#precision(myod, \"MYOD2\")\n",
    "#precision(fosl, \"FOSL1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4941adef",
   "metadata": {},
   "source": [
    "Precision for CTCF: 34.62 %\n",
    "\n",
    "Precision for STAT3: 1.28 %\n",
    "\n",
    "Precision for ETS1: 1.3 %\n",
    "\n",
    "Precision for MYOD2: 4.52 %\n",
    "\n",
    "Precision for FOSL1: 4.41 %\n",
    "\n",
    "The precisions do not change with increasing LLR. Model complexity is insufficient(High Bias, low variance --> underfitting). DNA sequence (motif) information alone is not enough for predicting TFBS, epigenetic modifications must be accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b03136",
   "metadata": {},
   "source": [
    "## 2.Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df186790",
   "metadata": {},
   "source": [
    "### a) Violin plots with box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin(data):\n",
    "    \n",
    "    plot_dict = {\"accessibility\": (1,1),\n",
    "                 \"DNAme\": (1,2),\n",
    "                 \"H2az\": (1,3),\n",
    "                 \"H3k27ac\": (1,4),\n",
    "                 \"H3k27me3\": (2,1),\n",
    "                 \"H3k36me3\": (2,2),\n",
    "                 \"H3k4me1\": (2,3),\n",
    "                 \"H3k4me2\": (2,4),\n",
    "                 \"H3k4me3\": (3,1),\n",
    "                 \"H3k79me2\": (3,2),\n",
    "                 \"H3k9ac\": (3,3),\n",
    "                 \"H3k9me3\": (3,4), \n",
    "                 \"H4k20me1\": (4,1), \n",
    "                 \"phylop\": (4,2), \n",
    "                 \"LLR\": (4,3)}\n",
    "    \n",
    "    cols_list = data.columns\n",
    "    \n",
    "    fig = make_subplots(rows=4, cols=4, subplot_titles=cols_list )\n",
    "    \n",
    "    for colname in cols_list:\n",
    "        \n",
    "        if bool(colname == \"tfbs\") is True:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "    \n",
    "            fig.add_trace(go.Violin(y=data[colname],\n",
    "                                    x=data[\"tfbs\"],\n",
    "                                    box_visible=True,\n",
    "                                    meanline_visible=True,\n",
    "                                    name=colname), plot_dict[colname][0], plot_dict[colname][1])\n",
    "\n",
    "            \n",
    "    fig.update_layout(title=\"Violin, correlations\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin(ctcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a964dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin(ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b90332",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin(myod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "violin(fosl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0302e2f",
   "metadata": {},
   "source": [
    "The base model appears to be making more precise predictions (34.63 %) for binding sites of CTCF. From the comparison of violin plots with other tfs, this should be a reason of lower epigenetic modifications for CTCF binding sites. The main distribution diffrence for predictions for CTCF is in the violin plot for DNAme. Therefore, DNMme could be a variable to add to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c9370",
   "metadata": {},
   "source": [
    "### b) Correlation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5aa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_heatmap(data):\n",
    "    \n",
    "    data = data.astype(float)\n",
    "    \n",
    "    correlation_list = []\n",
    "    \n",
    "    cols_list = data.columns\n",
    "    \n",
    "    for cols in cols_list:\n",
    "        for cols1 in cols_list:\n",
    "            \n",
    "            correlation = data[cols].corr(data[cols1])\n",
    "            \n",
    "            correlation_list.append(correlation)\n",
    "            \n",
    "    correlation_array = np.asarray(correlation_list)\n",
    "    \n",
    "    correlation_array = correlation_array.reshape((16, 16))\n",
    "    \n",
    "    df = pd.DataFrame(correlation_array, index=cols_list, columns=cols_list)\n",
    "    \n",
    "    heatmap_dict = {'z': df.values.tolist(),\n",
    "                    'x': df.columns.tolist(),\n",
    "                    'y': df.index.tolist()}\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(heatmap_dict))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_heatmap(ctcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_heatmap(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_heatmap(ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_heatmap(myod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413fc94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlations_heatmap(fosl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ae728",
   "metadata": {},
   "source": [
    "## 3) Logistic Regression Model & Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753868e0",
   "metadata": {},
   "source": [
    "I have built a model function (linear_regression1) with manual cross_validation steps. From the observations in the heatmaps higher correlation values are hints for potential variables to be eliminated (in case of overfitting). I selected the variables to be eliminated in the model from the strong correlation signals in the heatmaps. For ctcf the model started with 71 % of accuracy. But as it can be seen in the further steps, when functions logistic_regression and accuracy_evaluator come in the play with eliminated variables defined in them, the accuracy of ctcf did not decrease significantly for ctcf. Despite a slight increase in the precision for STAT3, the precision of the model is not as good precision of the base model, as it can make no predicitons for FOSL1, MYOD2 and ETS1\n",
    "\n",
    "This is the same when I built a the true model (model_evaluated) accounting for the variables extracted by the evaluations steps in def model_evaluations and def model.The model was tested for it's precision and accuracy by def accuracy_evaluator_evolved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression1(data):\n",
    "    \n",
    "    \"\"\"With manual cross-validation, variables selection is made with the help of heatmaps above\"\"\"\n",
    "    \n",
    "    data_cols = data.columns.to_series()\n",
    "    data_cols = data_cols[data_cols != \"tfbs\"] # if we put this variable in, the model works perfectly (duh!)\n",
    "    data_cols = data_cols[data_cols != \"accessibility\"]\n",
    "    data_cols = data_cols[data_cols != \"H2az\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k27ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k27me3\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k36me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me1\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k4me2\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k4me3\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k79me2\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H4k20me1\"]\n",
    "    #data_cols = data_cols[data_cols != \"phylop\"]\n",
    "    #data_cols = data_cols[data_cols != \"DNAme\"]\n",
    "    #data_cols = data_cols[data_cols != \"LLR\"]\n",
    "    \n",
    "    data_cols = data_cols.values\n",
    "    \n",
    "    X = data[data_cols]\n",
    "    y = data[\"tfbs\"]\n",
    "    \n",
    "    #  manual cross-validation\n",
    "    \n",
    "    X1_train,X1_test,y1_train,y1_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    X2_train,X2_test,y2_train,y2_test = train_test_split(X,y,test_size=0.10,random_state=1)\n",
    "    X3_train,X3_test,y3_train,y3_test = train_test_split(X,y,test_size=0.15,random_state=2)\n",
    "    X4_train,X4_test,y4_train,y4_test = train_test_split(X,y,test_size=0.05,random_state=3)\n",
    "    #X5_train,X5_test,y5_train,y5_test = train_test_split(X,y,test_size=0.25,random_state=4)\n",
    "    \n",
    "    logistic_regression = LogisticRegression()\n",
    "    \n",
    "    logistic_regression.fit(X1_train,y1_train)\n",
    "    \n",
    "    #sklearn.model_selection.cross_validate(logistic_regression, X, y) # default = 5-Fold\n",
    "    \n",
    "    logistic_regression.fit(X2_train,y2_train)\n",
    "    logistic_regression.fit(X3_train,y3_train)\n",
    "    logistic_regression.fit(X4_train,y4_train)\n",
    "    #logistic_regression.fit(X5_train,y5_train)\n",
    "    \n",
    "    return logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaf25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic_regression1(ctcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccaa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_evaluator(data, model):\n",
    "    \n",
    "    data_cols = data.columns.to_series()\n",
    "    data_cols = data_cols[data_cols != \"tfbs\"]\n",
    "    data_cols = data_cols[data_cols != \"accessibility\"]\n",
    "    data_cols = data_cols[data_cols != \"H2az\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k27ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k27me3\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k36me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me1\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k4me2\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k4me3\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k79me2\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H4k20me1\"]\n",
    "    #data_cols = data_cols[data_cols != \"phylop\"]\n",
    "    #data_cols = data_cols[data_cols != \"DNAme\"]\n",
    "    #data_cols = data_cols[data_cols != \"LLR\"]\n",
    "    \n",
    "    data_cols = data_cols.values\n",
    "    \n",
    "    X = data[data_cols]\n",
    "    y = data[\"tfbs\"]\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(y, y_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "    \n",
    "    print('Accuracy: ',metrics.accuracy_score(y, y_pred))\n",
    "    print('Precision: ',metrics.precision_score(y, y_pred, pos_label=\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator(ctcf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d84f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator(stat, model) # note the manual cross validation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator(ets, model) # result of overfitting(?), No predicitions are made by the model for ETS1 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ee871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_evaluator(myod, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcf24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_evaluator(fosl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe03d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_evaluator(ctcf, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_evaluator(stat, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cd0c0",
   "metadata": {},
   "source": [
    "## 4) Using RFE and Cross-Validation from sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluations(data):\n",
    "    \n",
    "    \"\"\"Cross Validation, RFE, using sklearn and all variables\"\"\"\n",
    "    \n",
    "    data_cols = data.columns.to_series()\n",
    "    data_cols = data_cols[data_cols != \"tfbs\"] \n",
    "    \n",
    "    data_cols = data_cols.values\n",
    "    \n",
    "    X = data[data_cols]\n",
    "    y = data[\"tfbs\"]\n",
    "    \n",
    "    models = dict()\n",
    "    \n",
    "    for i in range(2, 17):\n",
    "        selection = RFE(estimator=LogisticRegression(), n_features_to_select=i)\n",
    "        logistic_regression = LogisticRegression()\n",
    "        models[str(i)] = Pipeline(steps=[('s',selection),('m',logistic_regression)])\n",
    "    \n",
    "    # cross-validation\n",
    "    \n",
    "    def evaluate_model(model, X, y): # split = 0.20\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "        return scores\n",
    "        \n",
    "    results, names = list(), list()\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "\n",
    "            \n",
    "    pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stat = model_evaluations(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e53bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ets = model_evaluations(ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96537db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_myod = model_evaluations(myod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2500774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fosl = model_evaluations(fosl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctcf = model_evaluations(ctcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579da09",
   "metadata": {},
   "source": [
    "## ---->>  12  Variables to be seleceted for the model trained on CTCF data.\n",
    "\n",
    "The model cannot be trained by using other tf data ---> low rate of true positives may be an explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data, variable_count):\n",
    "    \n",
    "    \"\"\"Cross Validation, RFE, using sklearn and all variables\"\"\"\n",
    "    \n",
    "    data_cols = data.columns.to_series()\n",
    "    data_cols = data_cols[data_cols != \"tfbs\"] \n",
    "    #data_cols = data_cols[data_cols != \"accessibility\"]\n",
    "    #data_cols = data_cols[data_cols != \"H2az\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k27ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k27me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k36me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me1\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me2\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k79me2\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9ac\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k9me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H4k20me1\"]\n",
    "    #data_cols = data_cols[data_cols != \"phylop\"]\n",
    "    #data_cols = data_cols[data_cols != \"DNAme\"]\n",
    "    #data_cols = data_cols[data_cols != \"LLR\"]\n",
    "    \n",
    "    data_cols = data_cols.values\n",
    "    \n",
    "    X = data[data_cols]\n",
    "    y = data[\"tfbs\"]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    selection = RFE(estimator=LogisticRegression(), n_features_to_select=variable_count)\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps=[(\"s\",selection),(\"m\",model)])\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    \n",
    "    sklearn.model_selection.cross_validate(pipeline, X, y) # default: k = 5\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        print(\"Column: %d, Selected %s, Rank: %.3f\" % (i, selection.support_[i], selection.ranking_[i]))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcf5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_improved = model(ctcf, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_evaluator_evolved(data, model):\n",
    "    \n",
    "    data_cols = data.columns.to_series()\n",
    "    data_cols = data_cols[data_cols != \"tfbs\"]\n",
    "    #data_cols = data_cols[data_cols != \"accessibility\"] #0\n",
    "    #data_cols = data_cols[data_cols != \"H2az\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k27ac\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k27me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k36me3\"] #4\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me1\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k4me2\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k4me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H3k79me2\"]\n",
    "    data_cols = data_cols[data_cols != \"H3k9ac\"] #9\n",
    "    data_cols = data_cols[data_cols != \"H3k9me3\"]\n",
    "    #data_cols = data_cols[data_cols != \"H4k20me1\"]\n",
    "    #data_cols = data_cols[data_cols != \"phylop\"]\n",
    "    #data_cols = data_cols[data_cols != \"DNAme\"]\n",
    "    #data_cols = data_cols[data_cols != \"LLR\"] #14\n",
    "    \n",
    "    data_cols = data_cols.values\n",
    "    \n",
    "    X = data[data_cols]\n",
    "    y = data[\"tfbs\"]\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(y, y_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "    \n",
    "    print('Accuracy: ',metrics.accuracy_score(y, y_pred))\n",
    "    print('Precision: ',metrics.precision_score(y, y_pred, pos_label=\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator_evolved(ctcf, model_improved) #increase in precision of the model by 30 % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_evaluator_evolved(stat, model_improved) #increase in precision of the model by 6 % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecadfbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_evaluator_evolved(ets, model_improved) # same error for the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b42be",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Increasing variable numbers seem to improve precision for CTCF and STAT3 binding sites until variable_count = 12. Although the trade-off between variance and bias is accounted for in the evaluation of boxplots (to prohibit overfitting) the model is still lacking the ability of finding tfbs for ETS1, MYOD1 and FOSL2. The model cannot be generalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a673571",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip --allow-chromium-download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ccd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
